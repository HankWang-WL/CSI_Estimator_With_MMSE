# üõ± CSI Channel Estimation with Deep Learning

Channel State Information (CSI) Estimation in MIMO systems using lightweight deep learning models. This project implements compact neural networks (3D CNN, LSTM, Transformer) to estimate the channel matrix (H) from known pilot signals. These models significantly outperform a traditional MMSE estimator. Evaluation is conducted on two channel environments ‚Äì a synthetic i.i.d. Rayleigh fading channel and a realistic DeepMIMO ray-tracing channel ‚Äì to highlight generalization and robustness across channel conditions.

---

## üß† Project Highlights

* üì∂ **Multiple Channel Scenarios**: Supports synthetic Rayleigh fading (uncorrelated i.i.d. channels) and DeepMIMO ray-tracing data (real-world geometry with spatial correlation). This tests the models on both idealized and real-world channel characteristics.
* üßπ **Three Model Architectures**: Implemented 3D CNN, LSTM, and Transformer based estimators (each \~80K parameters) to learn CSI mapping from pilots.
* üß™ **MMSE Baseline Comparison**: Benchmarked against a traditional MMSE channel estimator under realistic conditions (varying SNR, hardware impairments) to quantify gains.
* üìà **Rich Visualizations**: Includes training loss curves, channel heatmaps (true vs. predicted H), and residual histograms of estimation error. These help interpret model performance per antenna and overall error distribution.
* ‚ö° **Deployment Focus**: Measured CUDA GPU inference time for each model (batch size 1 and 32) to assess real-time deployment feasibility.

---

## üñê System Model

We aim to estimate the MIMO channel matrix **H** using known pilot **x** and observed signal **y** under AWGN:

```
y = H ¬∑ x + n
```

Where:

* **x**: known pilot symbol, shape (N\_tx √ó L)
* **y**: received signal, shape (N\_rx √ó L)
* **H**: channel matrix, shape (N\_rx, N\_tx, L, 2)
* **n**: additive white Gaussian noise

Each training sample represents a single CSI frame ‚Äì we use L = 8 pilot subcarriers (spanning 8 frequencies in one OFDM symbol, similar to 5G NR CSI-RS patterns). The model learns to predict **ƒ§** (estimated H) from the input pair (x, y).

*Intuition*: The channel matrix H describes how each transmit antenna‚Äôs signal propagates to each receive antenna. Our neural networks learn to recover this matrix from the distorted pilot signals received, effectively learning the complex gain and phase introduced by the channel.

---

## üåê Channel Modeling: Rayleigh vs DeepMIMO

| Feature            | Rayleigh Channel                  | DeepMIMO (O1\_60)                          |
| ------------------ | --------------------------------- | ------------------------------------------ |
| Fading Model       | i.i.d. Complex Gaussian `CN(0,1)` | Ray-traced from real-world geometry        |
| Multi-path effect  | No (single tap)                   | Yes (multiple paths with delay & AoA/AoD)  |
| TX/RX correlation  | None                              | Present due to spatial layout              |
| Temporal diversity | No (flat response across pilots)  | Yes (each pilot gets distinct path phases) |
| Structure          | Uncorrelated, unstructured        | Geometrically constrained, structured      |
| Use case           | Baseline sanity test              | Realistic deployment setting               |

### üî¨ Power Delay Profile (PDP) Characteristics

**Rayleigh channel** is generated with exponential decay per tap:

```
h_l ~ CN(0, œÉ¬≤ ¬∑ e^(‚ÄìŒ±¬∑l))
```

**DeepMIMO channel** aggregates multiple geometric paths:

```
H(f) = Œ£‚Çö ‚àö(P‚Çö) ¬∑ e^(‚Äìj¬∑2œÄ¬∑f¬∑œÑ‚Çö) ¬∑ e^(j¬∑œï‚Çö) ¬∑ a_rx‚Çö ¬∑ a_tx‚Çö·¥¥
```

To introduce diversity across pilots, each path is perturbed with:

* random carrier frequency phase
* AoA/AoD steering response

This makes each subcarrier carry **distinct spatial features**, allowing learning-based models to outperform MMSE.

---

## üß™ Channel Data & Augmentations

We evaluate on two types of channel datasets, with on-the-fly augmentations to simulate real conditions:

* **Synthetic Rayleigh Fading**: Each channel coefficient `h_{i,j} ~ CN(0,1)` (complex Gaussian). All antenna pairs are i.i.d. with no correlation ‚Äì essentially a "white noise" channel. This provides a simple, uncorrelated scenario to test generalization.

* **DeepMIMO Ray-Tracing (O1\_60)**: Channels generated from a 3D ray-tracing scenario (DeepMIMO dataset). Multipath propagation and environment geometry create inherent TX/RX spatial correlation and structured channel taps. This represents a realistic urban microcell, challenging the model to exploit correlation and structure in the channel.

* **Augmentations & Impairments**: To improve realism and robustness, each training sample applies random conditions:

  * **Random SNR (Signal-to-Noise Ratio)**: Uniform between 10‚Äì30 dB for each sample, adding appropriate noise power.
  * **Random Pilot Sequence**: Uses Zadoff-Chu sequences with a random root index for each sample (simulating different pilot designs).
  * **IQ Imbalance (optional)**: Can simulate transmitter/receiver IQ gain-phase imbalance on the signals.
  * **1-bit Quantization Noise (optional)**: Optionally quantize signals to 1-bit (extreme case of ADC limitation).

These augmentations ensure the models are exposed to a variety of conditions and are not overfitting to ideal scenarios.

---

## üß† Models Implemented

| Model                 | Description                                                                                                             |
| --------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| **SimpleCSINet3D**    | 3D CNN that processes input as a volume across (Rx, Tx, pilots). \~80K params. Fast and effective for spatial features. |
| **LSTMCSINet**        | Treats pilots as sequential input. Captures frequency correlation. Best when channel response has structure across L.   |
| **TransformerCSINet** | Uses self-attention across pilot subcarriers. Learns global relationships among antennas and subcarriers.               |

**Input Format**: Each model receives input of shape `(batch, 4, N_rx, N_tx, L)`, where the 4 channels represent `[x_real, x_imag, y_real, y_imag]`. Real and imaginary parts of pilot and received signals are stacked along the channel dimension.

**Output Format**: The model outputs a predicted channel tensor ƒ§ of shape `(batch, N_rx, N_tx, L, 2)`, where the last dimension contains the real and imaginary components of the estimated channel matrix. Uses attention to model long-range pilot relationships |

---

## üìä Results & Visualizations

Below we present training results on both Rayleigh and DeepMIMO datasets for each model. We include:

- **Loss Curves**: Training vs. validation MSE loss across epochs. The dotted line indicates MMSE baseline.
- **Heatmaps**: Visual comparison of true vs. predicted channel magnitudes for a selected sample.
- **Residual Histograms**: Distribution of the element-wise difference between predicted and true channels.

| Dataset  | Model       | Loss Curve                                      | Heatmap                                       | Residual Histogram                                      |
| -------- | ----------- | ----------------------------------------------- | --------------------------------------------- | ------------------------------------------------------- |
| Rayleigh | CNN         | ![](results/Rayleigh_cnn_LossCurve.png)         | ![](results/Rayleigh_cnn_Heatmap.png)         | ![](results/Rayleigh_cnn_ResidualHistogram.png)         |
| Rayleigh | LSTM        | ![](results/Rayleigh_lstm_LossCurve.png)        | ![](results/Rayleigh_lstm_Heatmap.png)        | ![](results/Rayleigh_lstm_ResidualHistogram.png)        |
| Rayleigh | Transformer | ![](results/Rayleigh_transformer_LossCurve.png) | ![](results/Rayleigh_transformer_Heatmap.png) | ![](results/Rayleigh_transformer_ResidualHistogram.png) |
| DeepMIMO | CNN         | ![](results/DeepMIMO_cnn_LossCurve.png)         | ![](results/DeepMIMO_cnn_Heatmap.png)         | ![](results/DeepMIMO_cnn_ResidualHistogram.png)         |
| DeepMIMO | LSTM        | ![](results/DeepMIMO_lstm_LossCurve.png)        | ![](results/DeepMIMO_lstm_Heatmap.png)        | ![](results/DeepMIMO_lstm_ResidualHistogram.png)        |
| DeepMIMO | Transformer | ![](results/DeepMIMO_transformer_LossCurve.png) | ![](results/DeepMIMO_transformer_Heatmap.png) | ![](results/DeepMIMO_transformer_ResidualHistogram.png) |

**Figure Interpretation**:

- In **loss curves**, a lower validation loss indicates better generalization. Dotted horizontal lines indicate MMSE baseline loss.
- In **heatmaps**, more similar color patterns between prediction and ground truth imply better spatial reconstruction.
- In **residual histograms**, an ideal model shows error distribution centered at 0 with tight spread (low variance).

### üìã Performance Summary Table (Val MSE vs MMSE)

| Dataset  | Model       | Val MSE ‚Üì  | MMSE MSE (Baseline) | Notes                                                                                   |
|----------|-------------|------------|----------------------|-----------------------------------------------------------------------------------------|
| Rayleigh | **CNN**     | **0.0144** | 0.0297               | Best overall on Rayleigh; clean and stable convergence.                                 |
| Rayleigh | LSTM        | 0.0391     | 0.0295               | Underfits; sequential modeling ineffective for uncorrelated i.i.d. channels.            |
| Rayleigh | Transformer | 0.0186     | 0.0298               | Improved performance after epoch 7; good generalization.                                |
| DeepMIMO | **CNN**     | **0.0075** | 0.0369               | üèÜ **Best overall** (5√ó lower MSE than MMSE); highly effective at exploiting correlation.|
| DeepMIMO | LSTM        | 0.0195     | 0.0373               | Performs reasonably well but less consistent than Transformer.                          |
| DeepMIMO | Transformer | 0.0130     | 0.0375               | Strong results; benefits from structured multipath diversity.                           |



### üéØ Model Selection Insight

üí° **Key Takeaways**

- **LSTM Underfits (Not Overfitting)**  
  The LSTM model shows validation loss lower than training loss in both Rayleigh and DeepMIMO scenarios, indicating no overfitting. Instead, it likely underfits due to an architecture-data mismatch:  
  - The Rayleigh channel has no sequential structure (each subcarrier fading is independent), so LSTM‚Äôs time-series modeling offers little benefit.  
  - Aggressive dropout further reduces capacity, leading to under-utilization of the model.

- **Transformer Shows Delayed Gain**  
  The Transformer model often plateaus early (e.g., Rayleigh), then improves significantly after ~7‚Äì8 epochs. This suggests attention weights need more time to adapt.  
  - In DeepMIMO (with more inherent structure), Transformer converges smoothly and consistently outperforms LSTM.

- **3D CNN Excels**  
  Emerges as the best performer across both datasets. Achieves lowest MSE with stable, fast convergence.  
  - Especially in DeepMIMO, CNN reduces MSE from MMSE's 0.0369 to 0.0075 ‚Äî nearly **5√ó lower**, showing strong ability to capture spatial-frequency features.

- **Dropout Impact**  
  Dropout layers in CNN caused a noticeable train‚Äìval gap.  
  - Removing dropout led to tighter convergence and better generalization, suggesting models weren‚Äôt overfitting and regularization was unnecessary.


---
### ‚úÖ Future Improvements (Action Items)

- **ResNet-based Estimator**  
  Experiment with a ResNet-style deep CNN to explore whether skip connections can further improve estimation accuracy.

- **Longer Pilot Sequences**  
  Evaluate model robustness using longer pilot lengths (more subcarriers or time slots). This may allow LSTM/Transformer to leverage true sequential structure more effectively.

- **More DeepMIMO Scenarios**  
  Test on additional DeepMIMO scenes (e.g., O1_28, O2_60) to confirm generalization across different spatial layouts and carrier frequencies.

- **Transformer Tuning**  
  Adjust Transformer hyperparameters (e.g., insert LayerNorm, increase depth) to potentially close the performance gap with CNN on Rayleigh channels.

---
## üî¨ Inference Time (CUDA, batch size = 1/32)
We benchmarked the models' forward-pass inference latency on a single NVIDIA GPU (PyTorch, FP32). Even with similar parameter counts, architecture differences affect speed:
| Model       | Inference Time (ms) |
| ----------- | ------------------- |
| CNN         | 0.37 / 0.50         |
| LSTM        | 0.44 / 0.85         |
| Transformer | 0.83 / 1.13         |
Notes: The CNN is fastest, especially at batch=32 where it likely benefits from convolution parallelism. The Transformer is relatively slower due to attention computation overhead, which grows with sequence length (L=8 here is small, but still noticeable). LSTM is in between, but doesn‚Äôt scale as well to batch processing as CNN.
---

## üìÅ Project Structure

```
CSI_Estimator_With_MMSE/
‚îú‚îÄ‚îÄ main.py               # Training & evaluation pipeline (argument parsing, logging)
‚îú‚îÄ‚îÄ model.py              # Model definitions for CNN, LSTM, Transformer
‚îú‚îÄ‚îÄ dataset.py            # Dataset generator for Rayleigh and DeepMIMO channels
‚îú‚îÄ‚îÄ mmse_baseline.py      # MMSE estimator implementation for comparison
‚îú‚îÄ‚îÄ generate_deepmimo.py  # Script to generate DeepMIMO channel matrix data from DeepMIMO dataset files
‚îú‚îÄ‚îÄ run_all_combinations.py # Helper to run all model/dataset experiments in batch
‚îú‚îÄ‚îÄ config.py             # Centralized configuration (hyperparameters, flags)
‚îú‚îÄ‚îÄ results/              # Folder for output plots (loss curves, heatmaps, histograms)
‚îÇ   ‚îú‚îÄ‚îÄ Rayleigh_cnn_LossCurve.png, ...           # Training/validation loss plots for each scenario
‚îÇ   ‚îú‚îÄ‚îÄ Rayleigh_cnn_Heatmap.png, ...             # Heatmap of true vs predicted H for a sample
‚îÇ   ‚îî‚îÄ‚îÄ Rayleigh_cnn_ResidualHistogram.png, ...   # Histogram of estimation residuals
‚îú‚îÄ‚îÄ README.md             # *You are here* ‚Äì project overview and results
‚îî‚îÄ‚îÄ (other files like *.mat, *.pkl, *.pt are git-ignored due to size)

```

---

## üöÄ How to Run

Follow the steps below to set up and run the project:

---

### 1Ô∏èÔ∏è Install Dependencies

Make sure you're using **Python 3.8+**, then install the required packages:

```bash
pip install torch numpy matplotlib
```

---

### 2Ô∏èÔ∏è Prepare Data

* For **Rayleigh**, no external data is needed.
* For **DeepMIMO**, download the dataset (e.g., O1\_60 scenario) from the [DeepMIMO website](https://www.deepmimo.net/) and update the path in `config.py`.

(Optional) To generate H matrix samples from CIR:

```bash
python generate_deepmimo.py
```

---

### 3Ô∏èÔ∏è Train a Model

Run the training script with desired configuration:

```bash
python main.py --model=cnn --dataset=rayleigh
# options: --model=cnn/lstm/transformer
#          --dataset=rayleigh/deepmimo
```

Training progress and final metrics will be logged automatically.

---

### 4Ô∏èÔ∏è Reproduce All Experiments

To run all 3 models on both datasets and generate results used in the README:

```bash
python run_all_combinations.py
```

Plots and metrics will be saved under the `results/` folder.


---

## üë®‚Äçüíª Author

**Wang Chen Han**
5G PHY Algorithm Engineer
[github.com/HankWang-WL](https://github.com/HankWang-WL)
[hank851107@gmail.com](mailto:hank851107@gmail.com)


